{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Tuple\n",
    "from dataclasses import asdict\n",
    "import json\n",
    "\n",
    "@dataclass\n",
    "class TreeNode:\n",
    "    \"\"\"Class to store decision tree node information\"\"\"\n",
    "    # Unique identifier for the node in the tree\n",
    "    node_id: int\n",
    "    \n",
    "    # The name of the feature used for the decision at this node. \n",
    "    # If the node is a leaf, this will be `None`.\n",
    "    feature_name: Optional[str]\n",
    "    \n",
    "    # The threshold value for the feature used to split the data at this node. \n",
    "    # If the node is a leaf, this will be `None`.\n",
    "    threshold: Optional[float]\n",
    "    \n",
    "    # The node ID of the left child node. If the node is a leaf, this will be `None`.\n",
    "    left_child: Optional[int]\n",
    "    \n",
    "    # The node ID of the right child node. If the node is a leaf, this will be `None`.\n",
    "    right_child: Optional[int]\n",
    "    \n",
    "    # Indicates whether this node is a leaf node (`True` if leaf, `False` if internal).\n",
    "    is_leaf: bool\n",
    "    \n",
    "    # The class label predicted by the leaf node. \n",
    "    # Only set if the node is a leaf; otherwise, it is `None`.\n",
    "    class_label: Optional[str]\n",
    "    \n",
    "    # The number of samples (data points) that reached this node during training.\n",
    "    samples: int\n",
    "\n",
    "def extract_tree_structure(tree_classifier: DecisionTreeClassifier, feature_names: List[str], target_names: List[str]) -> List[TreeNode]: \n",
    "    \"\"\"\n",
    "    Extract node information from a trained DecisionTreeClassifier\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    tree_classifier : DecisionTreeClassifier\n",
    "        A trained sklearn DecisionTreeClassifier\n",
    "    feature_names : List[str]\n",
    "        A list of feature names\n",
    "    target_names : List[str]\n",
    "        A list of target class labels\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    List[TreeNode]\n",
    "        List of TreeNode objects containing the tree structure\n",
    "    \"\"\"\n",
    "    tree = tree_classifier.tree_\n",
    "    nodes = []\n",
    "\n",
    "    for node_id in range(tree.node_count):\n",
    "        # Check if node is leaf\n",
    "        is_leaf = tree.children_left[node_id] == -1\n",
    "\n",
    "        # Get node information\n",
    "        if is_leaf:\n",
    "            # Get the class label based on the majority class in the leaf\n",
    "            class_label_index = int(tree.value[node_id].argmax())\n",
    "            class_label = target_names[class_label_index]\n",
    "            \n",
    "            node = TreeNode(\n",
    "                node_id=node_id,\n",
    "                feature_name=None,\n",
    "                threshold=None,\n",
    "                left_child=None,\n",
    "                right_child=None,\n",
    "                is_leaf=True,\n",
    "                class_label=class_label,\n",
    "                samples=int(tree.n_node_samples[node_id])\n",
    "            )\n",
    "        else:\n",
    "            feature_name = feature_names[int(tree.feature[node_id])]\n",
    "            threshold = float(tree.threshold[node_id])\n",
    "            left_child = int(tree.children_left[node_id])\n",
    "            right_child = int(tree.children_right[node_id])\n",
    "\n",
    "            node = TreeNode(\n",
    "                node_id=node_id,\n",
    "                feature_name=feature_name,\n",
    "                threshold=threshold,\n",
    "                left_child=left_child,\n",
    "                right_child=right_child,\n",
    "                is_leaf=False,\n",
    "                class_label=None,\n",
    "                samples=int(tree.n_node_samples[node_id])\n",
    "            )\n",
    "\n",
    "        nodes.append(node)\n",
    "\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Features\n",
    "y = iris.target  # Labels\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "clf = clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_tree_to_json(nodes, filename: str, indent: int = 4):\n",
    "    \"\"\"\n",
    "    Save the tree structure to a JSON file\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    nodes : List[TreeNode]\n",
    "        List of TreeNode objects to save\n",
    "    filename : str\n",
    "        Path to save the JSON file\n",
    "    indent : int\n",
    "        Number of spaces for indentation\n",
    "    \"\"\"\n",
    "    # Convert TreeNodes to dictionaries\n",
    "    nodes_dict = [asdict(node) for node in nodes]\n",
    "    \n",
    "    # Save to file with indentation\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(nodes_dict, f, indent=indent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_tree_to_json(extract_tree_structure(clf, iris.feature_names, iris.target_names), filename=\"test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the code works for the iris dataset generated tree, let's try a bigger one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv (\"test_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['y_', 'ID', 'engine_age', 'length', 'power', 'month', 'landing',\n",
       "       'weight', 'value', 'value_cpi', 'price', 'y_month', 'year', 'patch',\n",
       "       'dist', 'patch_area', 'weight_lym', 'weight_lm', 'val_lm', 'val_lym',\n",
       "       'nao_index', 'surf_temp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_ : [1. 1. 0. ... 1. 0. 1.]\n",
      "ID : [1993001257 1993005128 1996007882 ... 2007039109 2001015121 2008043528]\n",
      "engine_age : [10. 26. 32. ...  3.  9.  8.]\n",
      "length : [10.5  21.3  12.13 ...  7.   14.16 35.49]\n",
      "power : [ 367.  970.  190. ...  144.  291. 1000.]\n",
      "month : [ 44 131 170 ... 124 121 198]\n",
      "landing : ['RISØR' 'BÅTSFJORD' 'ØKSNES' ... 'BØMLO' 'RØST' 'MÅSØY']\n",
      "weight : [5.0000e+00 1.9000e+01 0.0000e+00 ... 1.5000e+00 0.0000e+00 9.4625e+04]\n",
      "value : [9.5700000e+01 5.6459000e+02 0.0000000e+00 ... 1.9170000e+01 0.0000000e+00\n",
      " 5.0858288e+05]\n",
      "value_cpi : [1.1962000e+02 6.1169000e+02 0.0000000e+00 ... 2.0680000e+01 0.0000000e+00\n",
      " 4.8996424e+05]\n",
      "price : [19.14       29.71526316  0.         ... 12.78        0.\n",
      "  5.37472   ]\n",
      "y_month : [ 8 11  2 ...  4  1  6]\n",
      "year : [ 3. 10. 14. ... 10. 10. 16.]\n",
      "patch : ['09-16' '03-03' '04-27' ... '08-15' '07-26' '03-07']\n",
      "dist : [ 13.6  59.6 286.7 ...  10.6 457.5 220.2]\n",
      "patch_area : [3229 2122 4596 ... 1418 5377 2768]\n",
      "weight_lym : [0. 0. 0. ... 1. 0. 0.]\n",
      "weight_lm : [1.         0.37136675 0.         ... 0.         0.         0.        ]\n",
      "val_lm : [1.         0.35962817 0.         ... 0.         0.         0.        ]\n",
      "val_lym : [0. 0. 0. ... 1. 0. 0.]\n",
      "nao_index : [-0.07  -1.616  1.335 ... -0.72  -1.109 -0.433]\n",
      "surf_temp : [286.9  276.25 279.03 ... 287.35 279.31 277.65]\n"
     ]
    }
   ],
   "source": [
    "for col in list (df.columns):\n",
    "    print (col, \":\", df[col].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove \n",
    "# non numerical data \n",
    "# value adjusted for inflation (check dataset page for more info)\n",
    "# other non relevant/not known features \n",
    "df.drop([\"landing\", \"patch\", \"value_cpi\", \"y_\", \"ID\", \"dist\", \"patch_area\", \"weight_lym\", \"weight_lm\", \"val_lm\", \"val_lym\", \"nao_index\", \"price\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['engine_age', 'length', 'power', 'month', 'weight', 'value', 'y_month',\n",
       "       'year', 'surf_temp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"value\"]\n",
    "X = df[['engine_age', 'length', 'power', 'month', 'weight', 'y_month',\n",
    "       'year', 'surf_temp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make y categorical\n",
    "labels = [\n",
    "    \"Poor Session\", \"Below Average\", \"Average Session\", \"Above Average\", \n",
    "    \"Good Session\", \"Great Session\", \"Excellent Session\", \n",
    "    \"Outstanding\", \"Legendary\", \"Epic\"\n",
    "]\n",
    "# Split the values into 10 categories with meaningful labels\n",
    "y = pd.cut(y, bins=10, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a Decision Tree Classifier\n",
    "clf2 = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "clf2 = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_tree_to_json(extract_tree_structure(clf, feature_names=['engine_age', 'length', 'power', 'month', 'weight', 'y_month',\n",
    "       'year', 'surf_temp'], target_names=labels), filename=\"fishingTree.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
