{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this notebook will be to find the following data:\n",
    "* decision tree to plot in the visualization\n",
    "* the generated neighbourhood generated by LORE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything will be tested on the iris dataset for quick running times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"iris.json\"\n",
    "# Load and prepare data\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "feature_names = list(data.feature_names)\n",
    "target_names = list(data.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LORE initial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lore_sa.dataset import TabularDataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "        target  \n",
       "0       setosa  \n",
       "1       setosa  \n",
       "2       setosa  \n",
       "3       setosa  \n",
       "4       setosa  \n",
       "..         ...  \n",
       "145  virginica  \n",
       "146  virginica  \n",
       "147  virginica  \n",
       "148  virginica  \n",
       "149  virginica  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = {name: X[:, i] for i, name in enumerate(feature_names)}\n",
    "target_name = 'target'\n",
    "data_dict[target_name] = [target_names[i] for i in y]  # Map numerical targets to names\n",
    "\n",
    "dataset = TabularDataset.from_dict(data_dict, 'target')\n",
    "dataset.df.dropna(inplace = True)\n",
    "dataset.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lore_sa.bbox import sklearn_classifier_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model_generalized(dataset: TabularDataset, target_name:str, ):\n",
    "    numeric_indices = [v['index'] for k, v in dataset.descriptor['numeric'].items()]\n",
    "    categorical_indices = [v['index'] for k, v in dataset.descriptor['categorical'].items()]\n",
    "\n",
    "    # Create preprocessor using dynamic indices\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numeric_indices),\n",
    "            ('cat', OrdinalEncoder(), categorical_indices)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Remove rare classes with fewer than 2 instances\n",
    "    valid_classes = dataset.df[target_name].value_counts()[dataset.df[target_name].value_counts() > 1].index\n",
    "    dataset.df = dataset.df[dataset.df[target_name].isin(valid_classes)]\n",
    "\n",
    "        # Select features and target\n",
    "    X = dataset.df.iloc[:, numeric_indices + categorical_indices]  # Select all features\n",
    "    y = dataset.df[target_name]\n",
    "\n",
    "    # Split dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "    model = make_pipeline(preprocessor, RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return sklearn_classifier_bbox.sklearnBBox(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = train_model_generalized(dataset, target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'numeric': {'sepal length (cm)': {'index': 0,\n",
       "   'min': 4.3,\n",
       "   'max': 7.9,\n",
       "   'mean': 5.843333333333334,\n",
       "   'std': 0.828066127977863,\n",
       "   'median': 5.8,\n",
       "   'q1': 5.1,\n",
       "   'q3': 6.4},\n",
       "  'sepal width (cm)': {'index': 1,\n",
       "   'min': 2.0,\n",
       "   'max': 4.4,\n",
       "   'mean': 3.0573333333333337,\n",
       "   'std': 0.4358662849366982,\n",
       "   'median': 3.0,\n",
       "   'q1': 2.8,\n",
       "   'q3': 3.3},\n",
       "  'petal length (cm)': {'index': 2,\n",
       "   'min': 1.0,\n",
       "   'max': 6.9,\n",
       "   'mean': 3.7580000000000005,\n",
       "   'std': 1.7652982332594662,\n",
       "   'median': 4.35,\n",
       "   'q1': 1.6,\n",
       "   'q3': 5.1},\n",
       "  'petal width (cm)': {'index': 3,\n",
       "   'min': 0.1,\n",
       "   'max': 2.5,\n",
       "   'mean': 1.1993333333333336,\n",
       "   'std': 0.7622376689603465,\n",
       "   'median': 1.3,\n",
       "   'q1': 0.3,\n",
       "   'q3': 1.8}},\n",
       " 'categorical': {},\n",
       " 'ordinal': {},\n",
       " 'target': {'target': {'index': 4,\n",
       "   'distinct_values': ['setosa', 'versicolor', 'virginica'],\n",
       "   'count': {'setosa': 50, 'versicolor': 50, 'virginica': 50}}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.descriptor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoding decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original value: [5.1 3.5 1.4 0.2]\n",
      "Encoded value: [[5.1 3.5 1.4 0.2]]\n",
      "Decoded value: [[5.1 3.5 1.4 0.2]]\n"
     ]
    }
   ],
   "source": [
    "from lore_sa.encoder_decoder import ColumnTransformerEnc\n",
    "\n",
    "tabular_enc = ColumnTransformerEnc(dataset.descriptor)\n",
    "ref_value = dataset.df.iloc[0].values[:-1]\n",
    "encoded = tabular_enc.encode([ref_value])\n",
    "decoded = tabular_enc.decode(encoded)\n",
    "\n",
    "print(f\"Original value: {ref_value}\")\n",
    "print(f\"Encoded value: {encoded}\")\n",
    "print(f\"Decoded value: {decoded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the encoder is created using the dataset.descriptor, which is a dict so it can be saved to json and the encoder is then created based on the content read from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'numeric': {'sepal length (cm)': {'index': 0,\n",
       "   'min': 4.3,\n",
       "   'max': 7.9,\n",
       "   'mean': 5.843333333333334,\n",
       "   'std': 0.828066127977863,\n",
       "   'median': 5.8,\n",
       "   'q1': 5.1,\n",
       "   'q3': 6.4},\n",
       "  'sepal width (cm)': {'index': 1,\n",
       "   'min': 2.0,\n",
       "   'max': 4.4,\n",
       "   'mean': 3.0573333333333337,\n",
       "   'std': 0.4358662849366982,\n",
       "   'median': 3.0,\n",
       "   'q1': 2.8,\n",
       "   'q3': 3.3},\n",
       "  'petal length (cm)': {'index': 2,\n",
       "   'min': 1.0,\n",
       "   'max': 6.9,\n",
       "   'mean': 3.7580000000000005,\n",
       "   'std': 1.7652982332594662,\n",
       "   'median': 4.35,\n",
       "   'q1': 1.6,\n",
       "   'q3': 5.1},\n",
       "  'petal width (cm)': {'index': 3,\n",
       "   'min': 0.1,\n",
       "   'max': 2.5,\n",
       "   'mean': 1.1993333333333336,\n",
       "   'std': 0.7622376689603465,\n",
       "   'median': 1.3,\n",
       "   'q1': 0.3,\n",
       "   'q3': 1.8}},\n",
       " 'categorical': {},\n",
       " 'ordinal': {},\n",
       " 'target': {'target': {'index': 4,\n",
       "   'distinct_values': ['setosa', 'versicolor', 'virginica'],\n",
       "   'count': {'setosa': 50, 'versicolor': 50, 'virginica': 50}}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"descriptor.json\", \"w\") as f:\n",
    "    json.dump(dataset.descriptor, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the value to use for the prediction can be found via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.1, 3.5, 1.4, 0.2]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_value = dataset.df.iloc[0].values[:-1]\n",
    "list(ref_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and decoded using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.1, 3.5, 1.4, 0.2]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = tabular_enc.encode([ref_value])\n",
    "decoded = tabular_enc.decode(encoded)\n",
    "list(decoded[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### neighborhood generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lore_sa.neighgen import RandomGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "select the istance to explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal length (cm)    5.1\n",
       "sepal width (cm)     3.5\n",
       "petal length (cm)    1.4\n",
       "petal width (cm)     0.2\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_row = 0\n",
    "x = dataset.df.iloc[num_row][:-1]\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encode it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = tabular_enc.encode([x.values])[0] # remove the class feature from the input instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creates the neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2719209401317634],\n",
       "       [5.1, 3.5, 1.4, 0.2719209401317634],\n",
       "       [5.1, 3.5, 1.4, 0.2719209401317634],\n",
       "       [5.1, 4.099495992018104, 1.4, 0.2719209401317634],\n",
       "       [5.1, 4.099495992018104, 1.4, 0.2719209401317634],\n",
       "       [5.1, 4.099495992018104, 1.4, 0.2719209401317634],\n",
       "       [5.1, 4.099495992018104, 1.4, 2.021103121971574],\n",
       "       [5.1, 4.099495992018104, 2.8813667018435396, 0.3233529353842505],\n",
       "       [5.1, 4.099495992018104, 2.8813667018435396, 0.3233529353842505],\n",
       "       [5.1, 2.3039265925960324, 1.9098747190804515, 0.3233529353842505],\n",
       "       [5.1, 3.2716117120830877, 1.9098747190804515, 0.3233529353842505],\n",
       "       [5.367363474237033, 3.2716117120830877, 1.9098747190804515,\n",
       "        0.3233529353842505],\n",
       "       [5.367363474237033, 3.2716117120830877, 1.9098747190804515,\n",
       "        2.4717491904122637],\n",
       "       [5.367363474237033, 3.2716117120830877, 4.547596858325972,\n",
       "        2.4717491904122637],\n",
       "       [5.367363474237033, 3.2716117120830877, 4.547596858325972,\n",
       "        2.4717491904122637],\n",
       "       [5.367363474237033, 3.2716117120830877, 4.547596858325972,\n",
       "        2.4717491904122637],\n",
       "       [5.367363474237033, 3.2716117120830877, 4.547596858325972,\n",
       "        2.4717491904122637],\n",
       "       [5.367363474237033, 3.2716117120830877, 4.547596858325972,\n",
       "        2.4717491904122637],\n",
       "       [5.367363474237033, 3.2716117120830877, 4.547596858325972,\n",
       "        2.4717491904122637],\n",
       "       [5.367363474237033, 3.2716117120830877, 4.547596858325972,\n",
       "        2.4717491904122637],\n",
       "       [5.367363474237033, 3.3975310674893633, 3.6430599334928493,\n",
       "        2.133635846539946],\n",
       "       [5.367363474237033, 3.3975310674893633, 3.6430599334928493,\n",
       "        2.133635846539946],\n",
       "       [5.367363474237033, 3.842501506454844, 3.6430599334928493,\n",
       "        2.133635846539946],\n",
       "       [5.367363474237033, 3.842501506454844, 3.6430599334928493,\n",
       "        1.3410687745617118],\n",
       "       [5.367363474237033, 3.842501506454844, 5.515348671856364,\n",
       "        1.3410687745617118],\n",
       "       [5.367363474237033, 3.842501506454844, 5.515348671856364,\n",
       "        1.3410687745617118],\n",
       "       [5.367363474237033, 3.842501506454844, 5.515348671856364,\n",
       "        1.3410687745617118],\n",
       "       [7.536786443226925, 3.842501506454844, 5.515348671856364,\n",
       "        1.3410687745617118],\n",
       "       [7.536786443226925, 3.842501506454844, 5.515348671856364,\n",
       "        1.3410687745617118],\n",
       "       [6.6616627535463895, 4.252638963770991, 5.515348671856364,\n",
       "        1.3410687745617118],\n",
       "       [6.6616627535463895, 4.252638963770991, 5.515348671856364,\n",
       "        1.3410687745617118],\n",
       "       [6.6616627535463895, 4.252638963770991, 5.515348671856364,\n",
       "        1.3410687745617118],\n",
       "       [6.6616627535463895, 4.252638963770991, 5.515348671856364,\n",
       "        1.3410687745617118],\n",
       "       [6.6616627535463895, 4.252638963770991, 5.515348671856364,\n",
       "        1.3410687745617118],\n",
       "       [6.6616627535463895, 4.252638963770991, 5.515348671856364,\n",
       "        1.3410687745617118],\n",
       "       [6.6616627535463895, 4.252638963770991, 5.515348671856364,\n",
       "        1.3410687745617118],\n",
       "       [6.6616627535463895, 4.252638963770991, 5.515348671856364,\n",
       "        1.3410687745617118],\n",
       "       [6.6616627535463895, 4.252638963770991, 5.515348671856364,\n",
       "        1.2608775105875418],\n",
       "       [6.6616627535463895, 3.9063837796516796, 5.515348671856364,\n",
       "        1.2608775105875418],\n",
       "       [6.861697962441456, 3.9063837796516796, 5.515348671856364,\n",
       "        1.2608775105875418],\n",
       "       [6.861697962441456, 3.9063837796516796, 5.515348671856364,\n",
       "        1.2608775105875418],\n",
       "       [6.861697962441456, 3.9063837796516796, 5.515348671856364,\n",
       "        1.2608775105875418],\n",
       "       [6.861697962441456, 3.9063837796516796, 5.515348671856364,\n",
       "        0.44316116466883126],\n",
       "       [6.861697962441456, 3.9063837796516796, 5.515348671856364,\n",
       "        0.6557651413598672],\n",
       "       [6.861697962441456, 3.9063837796516796, 5.515348671856364,\n",
       "        0.7350161139546235],\n",
       "       [6.861697962441456, 3.9063837796516796, 5.515348671856364,\n",
       "        0.7350161139546235],\n",
       "       [6.861697962441456, 4.0479277733839965, 5.515348671856364,\n",
       "        0.7350161139546235],\n",
       "       [6.861697962441456, 2.2817222926505654, 5.515348671856364,\n",
       "        0.7350161139546235],\n",
       "       [6.861697962441456, 2.2817222926505654, 5.515348671856364,\n",
       "        0.7350161139546235],\n",
       "       [6.861697962441456, 2.2817222926505654, 5.515348671856364,\n",
       "        0.7350161139546235],\n",
       "       [6.861697962441456, 2.2817222926505654, 5.515348671856364,\n",
       "        2.053793226284715],\n",
       "       [7.318299600861026, 2.2817222926505654, 3.3676519774849707,\n",
       "        2.053793226284715],\n",
       "       [7.318299600861026, 2.2817222926505654, 3.3676519774849707,\n",
       "        2.053793226284715],\n",
       "       [7.318299600861026, 2.2817222926505654, 2.053404824991137,\n",
       "        0.912546001558672],\n",
       "       [7.318299600861026, 2.2817222926505654, 2.588039120827569,\n",
       "        0.912546001558672],\n",
       "       [6.971908041711744, 2.2817222926505654, 2.588039120827569,\n",
       "        0.912546001558672],\n",
       "       [6.971908041711744, 2.2817222926505654, 2.588039120827569,\n",
       "        0.912546001558672],\n",
       "       [6.971908041711744, 2.2817222926505654, 2.588039120827569,\n",
       "        0.912546001558672],\n",
       "       [5.746263592760628, 2.2817222926505654, 2.588039120827569,\n",
       "        0.912546001558672],\n",
       "       [5.746263592760628, 2.2817222926505654, 2.588039120827569,\n",
       "        0.912546001558672],\n",
       "       [5.746263592760628, 2.2817222926505654, 2.588039120827569,\n",
       "        0.912546001558672],\n",
       "       [5.746263592760628, 2.2817222926505654, 2.588039120827569,\n",
       "        0.912546001558672],\n",
       "       [5.746263592760628, 2.2817222926505654, 2.588039120827569,\n",
       "        0.912546001558672],\n",
       "       [5.746263592760628, 2.2817222926505654, 2.588039120827569,\n",
       "        0.912546001558672],\n",
       "       [5.746263592760628, 2.2817222926505654, 2.588039120827569,\n",
       "        0.912546001558672],\n",
       "       [5.746263592760628, 2.2817222926505654, 2.588039120827569,\n",
       "        0.912546001558672],\n",
       "       [5.746263592760628, 2.2817222926505654, 2.588039120827569,\n",
       "        0.912546001558672],\n",
       "       [5.746263592760628, 2.2817222926505654, 2.588039120827569,\n",
       "        0.912546001558672],\n",
       "       [5.746263592760628, 3.035719520221181, 2.588039120827569,\n",
       "        0.912546001558672],\n",
       "       [5.746263592760628, 3.035719520221181, 2.588039120827569,\n",
       "        1.268350534246854],\n",
       "       [5.746263592760628, 3.035719520221181, 2.588039120827569,\n",
       "        1.268350534246854],\n",
       "       [5.746263592760628, 3.035719520221181, 2.588039120827569,\n",
       "        1.268350534246854],\n",
       "       [5.746263592760628, 3.035719520221181, 2.588039120827569,\n",
       "        1.268350534246854],\n",
       "       [5.746263592760628, 3.035719520221181, 2.588039120827569,\n",
       "        1.268350534246854],\n",
       "       [5.746263592760628, 3.035719520221181, 2.588039120827569,\n",
       "        1.268350534246854],\n",
       "       [5.746263592760628, 3.035719520221181, 2.588039120827569,\n",
       "        0.9326125642348551],\n",
       "       [5.746263592760628, 3.035719520221181, 2.588039120827569,\n",
       "        0.9326125642348551],\n",
       "       [5.746263592760628, 3.035719520221181, 2.588039120827569,\n",
       "        0.9326125642348551],\n",
       "       [5.746263592760628, 3.035719520221181, 2.588039120827569,\n",
       "        0.9326125642348551],\n",
       "       [5.746263592760628, 3.035719520221181, 2.588039120827569,\n",
       "        0.9326125642348551],\n",
       "       [5.746263592760628, 3.035719520221181, 2.588039120827569,\n",
       "        0.9326125642348551],\n",
       "       [5.746263592760628, 3.035719520221181, 2.588039120827569,\n",
       "        0.9326125642348551],\n",
       "       [5.746263592760628, 3.035719520221181, 2.588039120827569,\n",
       "        0.9326125642348551],\n",
       "       [5.746263592760628, 3.035719520221181, 2.588039120827569,\n",
       "        0.9326125642348551],\n",
       "       [5.746263592760628, 3.035719520221181, 2.588039120827569,\n",
       "        0.9326125642348551],\n",
       "       [5.142341741209432, 3.035719520221181, 2.588039120827569,\n",
       "        2.3572309444637],\n",
       "       [5.142341741209432, 3.035719520221181, 2.588039120827569,\n",
       "        2.3572309444637],\n",
       "       [5.142341741209432, 3.035719520221181, 2.588039120827569,\n",
       "        2.3572309444637],\n",
       "       [5.142341741209432, 3.2015973305959102, 2.588039120827569,\n",
       "        2.3572309444637],\n",
       "       [5.142341741209432, 3.2015973305959102, 2.588039120827569,\n",
       "        2.3572309444637],\n",
       "       [7.061090906888909, 3.2015973305959102, 4.781546017516808,\n",
       "        2.3572309444637],\n",
       "       [7.061090906888909, 3.2015973305959102, 4.781546017516808,\n",
       "        2.3572309444637],\n",
       "       [4.882837811347466, 3.2015973305959102, 4.781546017516808,\n",
       "        2.3572309444637],\n",
       "       [5.534820130907652, 3.2015973305959102, 4.781546017516808,\n",
       "        2.3572309444637],\n",
       "       [5.534820130907652, 3.2015973305959102, 4.781546017516808,\n",
       "        2.3572309444637],\n",
       "       [5.534820130907652, 3.2015973305959102, 4.781546017516808,\n",
       "        2.3572309444637],\n",
       "       [5.534820130907652, 3.2015973305959102, 2.9290497933523003,\n",
       "        2.3572309444637],\n",
       "       [6.9953405968922855, 3.2015973305959102, 2.9290497933523003,\n",
       "        2.223201065702852],\n",
       "       [6.9953405968922855, 3.2015973305959102, 2.9290497933523003,\n",
       "        2.223201065702852],\n",
       "       [6.9953405968922855, 3.2015973305959102, 2.9374033156721158,\n",
       "        2.223201065702852]], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = RandomGenerator(bbox=bbox, dataset=dataset, encoder=tabular_enc, ocr=0.1)\n",
    "neighbour = gen.generate(z, 100, dataset.descriptor, tabular_enc)\n",
    "neighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### surrogate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lore_sa.surrogate import DecisionTreeSurrogate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create X, y and yz for the decision tree surrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode the neighborhood to be labeled by the blackbox model\n",
    "neighb_train_X = tabular_enc.decode(neighbour)\n",
    "neighb_train_y = bbox.predict(neighb_train_X)\n",
    "# encode the target class to the surrogate model\n",
    "neighb_train_yz = tabular_enc.encode_target_class(neighb_train_y.reshape(-1, 1)).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the surrogate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeSurrogate()\n",
    "x = dt.train(neighbour, neighb_train_yz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data extraction for the plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the decision tree _tree for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.tree._tree.Tree at 0x27828140a40>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.get_dt().tree_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils file in decision tree visualization prototype folder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional\n",
    "from dataclasses import asdict\n",
    "import json\n",
    "from sklearn.tree._tree import Tree \n",
    "\n",
    "@dataclass\n",
    "class TreeNode:\n",
    "    \"\"\"Class to store decision tree node information\"\"\"\n",
    "    # Unique identifier for the node in the tree\n",
    "    node_id: int\n",
    "    \n",
    "    # The name of the feature used for the decision at this node. \n",
    "    # If the node is a leaf, this will be `None`.\n",
    "    feature_name: Optional[str]\n",
    "    \n",
    "    # The threshold value for the feature used to split the data at this node. \n",
    "    # If the node is a leaf, this will be `None`.\n",
    "    threshold: Optional[float]\n",
    "    \n",
    "    # The node ID of the left child node. If the node is a leaf, this will be `None`.\n",
    "    left_child: Optional[int]\n",
    "    \n",
    "    # The node ID of the right child node. If the node is a leaf, this will be `None`.\n",
    "    right_child: Optional[int]\n",
    "    \n",
    "    # Indicates whether this node is a leaf node (`True` if leaf, `False` if internal).\n",
    "    is_leaf: bool\n",
    "    \n",
    "    # The class label predicted by the leaf node. \n",
    "    # Only set if the node is a leaf; otherwise, it is `None`.\n",
    "    class_label: Optional[str]\n",
    "    \n",
    "    # The number of samples (data points) that reached this node during training.\n",
    "    samples: int\n",
    "\n",
    "def extract_tree_structure(tree_classifier: DecisionTreeClassifier, feature_names: List[str], target_names: List[str]) -> List[TreeNode]: \n",
    "    \"\"\"\n",
    "    Extract node information from a trained DecisionTreeClassifier\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    tree_classifier : DecisionTreeClassifier\n",
    "        A trained sklearn DecisionTreeClassifier\n",
    "    feature_names : List[str]\n",
    "        A list of feature names\n",
    "    target_names : List[str]\n",
    "        A list of target class labels\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    List[TreeNode]\n",
    "        List of TreeNode objects containing the tree structure\n",
    "    \"\"\"\n",
    "    if isinstance(tree_classifier, DecisionTreeClassifier): #account for LORE DecisionTreeSurrogate class\n",
    "        tree = tree_classifier.tree_\n",
    "    else:\n",
    "        tree = tree_classifier\n",
    "\n",
    "    nodes = []\n",
    "\n",
    "    for node_id in range(tree.node_count):\n",
    "        # Check if node is leaf\n",
    "        is_leaf = tree.children_left[node_id] == -1\n",
    "\n",
    "        # Get node information\n",
    "        if is_leaf:\n",
    "            # Get the class label based on the majority class in the leaf\n",
    "            class_label_index = int(tree.value[node_id].argmax())\n",
    "            class_label = target_names[class_label_index]\n",
    "            \n",
    "            node = TreeNode(\n",
    "                node_id=node_id,\n",
    "                feature_name=None,\n",
    "                threshold=None,\n",
    "                left_child=None,\n",
    "                right_child=None,\n",
    "                is_leaf=True,\n",
    "                class_label=class_label,\n",
    "                samples=int(tree.n_node_samples[node_id])\n",
    "            )\n",
    "        else:\n",
    "            feature_name = feature_names[int(tree.feature[node_id])]\n",
    "            threshold = float(tree.threshold[node_id])\n",
    "            left_child = int(tree.children_left[node_id])\n",
    "            right_child = int(tree.children_right[node_id])\n",
    "\n",
    "            node = TreeNode(\n",
    "                node_id=node_id,\n",
    "                feature_name=feature_name,\n",
    "                threshold=threshold,\n",
    "                left_child=left_child,\n",
    "                right_child=right_child,\n",
    "                is_leaf=False,\n",
    "                class_label=None,\n",
    "                samples=int(tree.n_node_samples[node_id])\n",
    "            )\n",
    "\n",
    "        nodes.append(node)\n",
    "\n",
    "    return nodes\n",
    "\n",
    "def save_tree_to_json(nodes, filename: str, indent: int = 4):\n",
    "    \"\"\"\n",
    "    Save the tree structure to a JSON file\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    nodes : List[TreeNode]\n",
    "        List of TreeNode objects to save\n",
    "    filename : str\n",
    "        Path to save the JSON file\n",
    "    indent : int\n",
    "        Number of spaces for indentation\n",
    "    \"\"\"\n",
    "    # Convert TreeNodes to dictionaries\n",
    "    nodes_dict = [asdict(node) for node in nodes]\n",
    "    \n",
    "    # Save to file with indentation\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(nodes_dict, f, indent=indent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_tree_to_json(extract_tree_structure(dt.get_dt().tree_, feature_names=['engine_age', 'length', 'power', 'month', 'weight', 'y_month',\n",
    "       'year', 'surf_temp'], target_names=target_names), filename=\"loreTreeTest.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.get_dt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_pca_visualization_data in the PCA proptotype folder file code \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import json\n",
    "from scipy.spatial import Voronoi\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import unary_union\n",
    "import networkx as nx\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def preprocess_data(X):\n",
    "    \"\"\"\n",
    "    Standardize the data and apply PCA transformation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array-like\n",
    "        Input features\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (transformed_data, pca_model, scaler_model)\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    pca = PCA(n_components=2)\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    return X_pca, pca, scaler\n",
    "\n",
    "def generate_decision_boundary_grid(X_pca, step=0.1):\n",
    "    \"\"\"\n",
    "    Generate a grid for decision boundary visualization.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_pca : array-like\n",
    "        PCA transformed features\n",
    "    step : float, default=0.1\n",
    "        Step size for the grid\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (xx, yy) meshgrid arrays and (x_min, x_max, y_min, y_max) boundaries\n",
    "    \"\"\"\n",
    "    x_min, x_max = X_pca[:, 0].min() - 1, X_pca[:, 0].max() + 1\n",
    "    y_min, y_max = X_pca[:, 1].min() - 1, X_pca[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(\n",
    "        np.arange(x_min, x_max, step),\n",
    "        np.arange(y_min, y_max, step)\n",
    "    )\n",
    "    return xx, yy, (x_min, x_max, y_min, y_max)\n",
    "\n",
    "def filter_points_by_class_kmeans(points, labels, threshold=500, threshold_multiplier=4, random_state=42):\n",
    "    \"\"\"\n",
    "    Filter points using K-means clustering to reduce data density.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    points : array-like\n",
    "        Input points to filter\n",
    "    labels : array-like\n",
    "        Class labels for points\n",
    "    threshold : int, default=500\n",
    "        Maximum number of points per class\n",
    "    threshold_multiplier : int, default=4\n",
    "        Multiplier for initial sampling size\n",
    "    random_state : int, default=42\n",
    "        Random state for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (filtered_points, filtered_labels)\n",
    "    \"\"\"\n",
    "    filtered_points = []\n",
    "    filtered_labels = []\n",
    "    unique_classes = np.unique(labels)\n",
    "\n",
    "    for cls in unique_classes:\n",
    "        class_indices = np.where(labels == cls)[0]\n",
    "        class_points = points[class_indices]\n",
    "        n_points = len(class_points)\n",
    "\n",
    "        if n_points > threshold:\n",
    "            sample_size = min(threshold * threshold_multiplier, n_points)\n",
    "            rng = np.random.RandomState(random_state)\n",
    "            sampled_indices = rng.choice(n_points, size=sample_size, replace=False)\n",
    "            sampled_points = class_points[sampled_indices]\n",
    "\n",
    "            kmeans = KMeans(n_clusters=threshold, random_state=random_state, n_init=10)\n",
    "            kmeans.fit(sampled_points)\n",
    "            centroids = kmeans.cluster_centers_\n",
    "\n",
    "            selected_points = []\n",
    "            for centroid in centroids:\n",
    "                distances = np.linalg.norm(class_points - centroid, axis=1)\n",
    "                closest_index = np.argmin(distances)\n",
    "                selected_points.append(class_points[closest_index])\n",
    "\n",
    "            selected_points = np.array(selected_points)\n",
    "        else:\n",
    "            selected_points = class_points\n",
    "\n",
    "        filtered_points.append(selected_points)\n",
    "        filtered_labels.extend([cls] * len(selected_points))\n",
    "\n",
    "    return np.vstack(filtered_points), np.array(filtered_labels)\n",
    "\n",
    "def create_voronoi_regions(xx, yy, Z):\n",
    "    \"\"\"\n",
    "    Create Voronoi regions for decision boundaries.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    xx : array-like\n",
    "        X coordinates of the grid\n",
    "    yy : array-like\n",
    "        Y coordinates of the grid\n",
    "    Z : array-like\n",
    "        Predicted classes for the grid points\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (merged_regions, merged_classes)\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "    vor = Voronoi(np.c_[xx.ravel(), yy.ravel()])\n",
    "    regions, vertices = vor.regions, vor.vertices\n",
    "\n",
    "    region_class_map = {}\n",
    "    region_polygons = []\n",
    "    region_class_list = []\n",
    "    region_index_map = {}\n",
    "\n",
    "    polygon_idx = 0\n",
    "    for point_index, region_index in enumerate(vor.point_region):\n",
    "        region = regions[region_index]\n",
    "        if not -1 in region and len(region) > 0:\n",
    "            polygon = Polygon([vertices[i] for i in region])\n",
    "            region_polygons.append(polygon)\n",
    "            region_class_map[region_index] = Z.ravel()[point_index]\n",
    "            region_class_list.append(Z.ravel()[point_index])\n",
    "            region_index_map[region_index] = polygon_idx\n",
    "            G.add_node(region_index)\n",
    "            polygon_idx += 1\n",
    "\n",
    "    # Find adjacent regions\n",
    "    for (p1, p2), ridge_vertices in zip(vor.ridge_points, vor.ridge_vertices):\n",
    "        if -1 in ridge_vertices:\n",
    "            continue\n",
    "        r1, r2 = vor.point_region[p1], vor.point_region[p2]\n",
    "        \n",
    "        if region_class_map.get(r1) == region_class_map.get(r2):\n",
    "            G.add_edge(r1, r2)\n",
    "\n",
    "    # Merge connected regions\n",
    "    merged_regions = []\n",
    "    merged_classes = []\n",
    "\n",
    "    for component in nx.connected_components(G):\n",
    "        merged_polygon = unary_union([\n",
    "            region_polygons[region_index_map[i]] \n",
    "            for i in component \n",
    "            if i in region_index_map\n",
    "        ])\n",
    "        merged_regions.append(merged_polygon)\n",
    "        merged_classes.append(region_class_map[list(component)[0]])\n",
    "\n",
    "    return merged_regions, merged_classes\n",
    "\n",
    "def format_pc_label(pc_loadings, feature_names, pc_index):\n",
    "    \"\"\"\n",
    "    Format the principal component label with feature contributions.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    pc_loadings : array-like\n",
    "        Principal component loadings\n",
    "    feature_names : list\n",
    "        List of feature names\n",
    "    pc_index : int\n",
    "        Index of the principal component\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        Formatted label\n",
    "    \"\"\"\n",
    "    return f\"PC{pc_index + 1}: \" + \", \".join(\n",
    "        [f\"{name} ({value:+.2f})\" for name, value in zip(feature_names, pc_loadings)]\n",
    "    )\n",
    "\n",
    "def generate_pca_visualization_data(data_file, feature_names, target_names, X, y, pretrained_tree, step=0.1):\n",
    "    \"\"\"\n",
    "    Generate PCA visualization data and decision boundaries for a pre-trained decision tree.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_file : str\n",
    "        Path to output JSON file\n",
    "    feature_names : list\n",
    "        List of feature names\n",
    "    target_names : list\n",
    "        List of target class names\n",
    "    X : array-like\n",
    "        Input features\n",
    "    y : array-like\n",
    "        Target labels\n",
    "    pretrained_tree : DecisionTreeClassifier\n",
    "        Pre-trained decision tree classifier on original (non-PCA) data\n",
    "    step : float, default=0.1\n",
    "        Step size for decision boundary grid\n",
    "    \"\"\"\n",
    "    # Transform data\n",
    "    X_pca, pca, scaler = preprocess_data(X)\n",
    "    \n",
    "    # Generate grid in PCA space\n",
    "    xx, yy, (x_min, x_max, y_min, y_max) = generate_decision_boundary_grid(X_pca, step)\n",
    "    \n",
    "    # Transform grid points back to original space for prediction\n",
    "    grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "    grid_original = pca.inverse_transform(grid_points)\n",
    "    grid_original = scaler.inverse_transform(grid_original)\n",
    "    \n",
    "    # Get predictions using the pre-trained tree\n",
    "    Z = pretrained_tree.predict(grid_original).reshape(xx.shape)\n",
    "    \n",
    "    # Filter PCA points\n",
    "    filtered_pca_data, filtered_labels = filter_points_by_class_kmeans(\n",
    "        X_pca, y, threshold=2000, threshold_multiplier=5\n",
    "    )\n",
    "    \n",
    "    # Create Voronoi regions\n",
    "    merged_regions, merged_classes = create_voronoi_regions(xx, yy, Z)\n",
    "    \n",
    "    # Format PC labels\n",
    "    pc1_label = format_pc_label(pca.components_[0], feature_names, 0)\n",
    "    pc2_label = format_pc_label(pca.components_[1], feature_names, 1)\n",
    "    \n",
    "    # Prepare visualization data\n",
    "    visualization_data = {\n",
    "        \"pcaData\": filtered_pca_data.tolist(),\n",
    "        \"targets\": filtered_labels.tolist(),\n",
    "        \"decisionBoundary\": {\n",
    "            \"regions\": [list(p.exterior.coords) for p in merged_regions],\n",
    "            \"regionClasses\": [int(c) for c in merged_classes],\n",
    "            \"xRange\": [float(x_min), float(x_max)],\n",
    "            \"yRange\": [float(y_min), float(y_max)],\n",
    "        },\n",
    "        \"xAxisLabel\": pc1_label,\n",
    "        \"yAxisLabel\": pc2_label,\n",
    "    }\n",
    "    \n",
    "    # Save to file\n",
    "    with open(data_file, \"w\") as f:\n",
    "        json.dump(visualization_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_pca_visualization_data (\n",
    "    data_file=\"lorePCATest.json\", \n",
    "    feature_names=feature_names, \n",
    "    target_names=target_names, \n",
    "    X=neighb_train_X, \n",
    "    y=neighb_train_y, \n",
    "    pretrained_tree=dt.get_dt(), \n",
    "    step = 0.1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
