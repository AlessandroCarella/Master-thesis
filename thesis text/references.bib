

@article{alicioglu2021survey,
    author = {Gulsum Alicioglu and Bo Sun},
    title = {A survey of visual analytics for Explainable Artificial Intelligence methods},
    journal = {Computers \& Graphics},
    volume = {102},
    pages = {502-520},
    year = {2022},
    issn = {0097-8493},
    doi = {https://doi.org/10.1016/j.cag.2021.09.002},
    url = {https://www.sciencedirect.com/science/article/pii/S0097849321001886},
    keywords = {Explainable Artificial Intelligence, Interpretable neural networks, Visual analytics, Black-box models},
    abstract = {Deep learning (DL) models have achieved impressive performance in various domains such as medicine, finance, and autonomous vehicle systems with advances in computing power and technologies. However, due to the black-box structure of DL models, the decisions of these learning models often need to be explained to end-users. Explainable Artificial Intelligence (XAI) provides explanations of black-box models to reveal the behavior and underlying decision-making mechanisms of the models through tools, techniques, and algorithms. Visualization techniques help to present model and prediction explanations in a more understandable, explainable, and interpretable way. This survey paper aims to review current trends and challenges of visual analytics in interpreting DL models by adopting XAI methods and present future research directions in this area. We reviewed literature based on two different aspects, model usage and visual approaches. We addressed several research questions based on our findings and then discussed missing points, research gaps, and potential future research directions. This survey provides guidelines to develop a better interpretation of neural networks through XAI methods in the field of visual analytics.}
}

@misc{bodria2023benchmarking,
    title={Benchmarking and Survey of Explanation Methods for Black Box Models}, 
    author={Francesco Bodria and Fosca Giannotti and Riccardo Guidotti and Francesca Naretto and Dino Pedreschi and Salvatore Rinzivillo},
    year={2021},
    eprint={2102.13076},
    archivePrefix={arXiv},
    primaryClass={cs.AI},
    url={https://arxiv.org/abs/2102.13076}, 
}

@article{gunning2019darpa,
    title={DARPA's Explainable Artificial Intelligence (XAI) Program},
    author={David Gunning and David W. Aha},
    journal={AI Mag.},
    year={2019},
    volume={40},
    pages={44-58},
    url={https://api.semanticscholar.org/CorpusID:67773377}
}

@article{miller2019explanation,
  title={Explanation in Artificial Intelligence: Insights from the Social Sciences},
  author={Tim Miller},
  journal={ArXiv},
  year={2017},
  volume={abs/1706.07269},
  url={https://api.semanticscholar.org/CorpusID:36024272}
}

@article{emmert2020explainable,
    title={Explainable artificial intelligence and machine learning: A reality rooted perspective},
    volume={10},
    ISSN={1942-4795},
    url={http://dx.doi.org/10.1002/widm.1368},
    DOI={10.1002/widm.1368},
    number={6},
    journal={WIREs Data Mining and Knowledge Discovery},
    publisher={Wiley},
    author={Emmert‐Streib, Frank and Yli‐Harja, Olli and Dehmer, Matthias},
    year={2020},
    month=jun 
}

@article{adadi2018peeking,
    author={Adadi, Amina and Berrada, Mohammed},
    journal={IEEE Access}, 
    title={Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI)}, 
    year={2018},
    volume={6},
    number={},
    pages={52138-52160},
    keywords={Conferences;Machine learning;Market research;Prediction algorithms;Machine learning algorithms;Biological system modeling;Explainable artificial intelligence;interpretable machine learning;black-box models},
    doi={10.1109/ACCESS.2018.2870052}
}

@misc{das2020opportunities,
    title={Opportunities and Challenges in Explainable Artificial Intelligence (XAI): A Survey}, 
    author={Arun Das and Paul Rad},
    year={2020},
    eprint={2006.11371},
    archivePrefix={arXiv},
    primaryClass={cs.CV},
    url={https://arxiv.org/abs/2006.11371}, 
}

@misc{ribeiro2016should,
    title={"Why Should I Trust You?": Explaining the Predictions of Any Classifier}, 
    author={Marco Tulio Ribeiro and Sameer Singh and Carlos Guestrin},
    year={2016},
    eprint={1602.04938},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    url={https://arxiv.org/abs/1602.04938},
    booktitle = {}
}

% SHAP
@misc{lundberg2017unified,
      title={A Unified Approach to Interpreting Model Predictions}, 
      author={Scott Lundberg and Su-In Lee},
      year={2017},
      eprint={1705.07874},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1705.07874}, 
}

@article{guidotti2022stable,
    author = {Guidotti, Riccardo and Monreale, Anna and Ruggieri, Salvatore and Naretto, Francesca and Turini, Franco and Pedreschi, Dino and Giannotti, Fosca},
    title = {Stable and actionable explanations of black-box models through factual and counterfactual rules},
    year = {2022},
    issue_date = {Sep 2024},
    publisher = {Kluwer Academic Publishers},
    address = {USA},
    volume = {38},
    number = {5},
    issn = {1384-5810},
    url = {https://doi.org/10.1007/s10618-022-00878-5},
    doi = {10.1007/s10618-022-00878-5},
    abstract = {Recent years have witnessed the rise of accurate but obscure classification models that hide the logic of their internal decision processes. Explaining the decision taken by a black-box classifier on a specific input instance is therefore of striking interest. We propose a local rule-based model-agnostic explanation method providing stable and actionable explanations. An explanation consists of a factual logic rule, stating the reasons for the black-box decision, and a set of actionable counterfactual logic rules, proactively suggesting the changes in the instance that lead to a different outcome. Explanations are computed from a decision tree that mimics the behavior of the black-box locally to the instance to explain. The decision tree is obtained through a bagging-like approach that favors stability and fidelity: first, an ensemble of decision trees is learned from neighborhoods of the instance under investigation; then, the ensemble is merged into a single decision tree. Neighbor instances are synthetically generated through a genetic algorithm whose fitness function is driven by the black-box behavior. Experiments show that the proposed method advances the state-of-the-art towards a comprehensive approach that successfully covers stability and actionability of factual and counterfactual explanations.},
    journal = {Data Min. Knowl. Discov.},
    month = nov,
    pages = {2825–2862},
    numpages = {38},
    keywords = {Explainable AI, Local explanations, Model-agnostic explanations, Rule-based explanations, Counterfactuals}
}


@article{guidotti2019lore,
    title={Factual and Counterfactual Explanations for Black Box Decision Making},
    author={Riccardo Guidotti and Anna Monreale and Fosca Giannotti and Dino Pedreschi and Salvatore Ruggieri and Franco Turini},
    journal={IEEE Intelligent Systems},
    year={2019},
    volume={34},
    pages={14-23},
    url={https://api.semanticscholar.org/CorpusID:210931542}
}

@misc{mcinnes2020umap,
    title={UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction}, 
    author={Leland McInnes and John Healy and James Melville},
    year={2020},
    eprint={1802.03426},
    archivePrefix={arXiv},
    primaryClass={stat.ML},
    url={https://arxiv.org/abs/1802.03426}, 
}

@article{becht2019evaluation,
    title={Dimensionality reduction for visualizing single-cell data using UMAP},
    author={Etienne Becht and Leland McInnes and John Healy and Charles-Antoine Dutertre and Immanuel Kwok and Lai Guan Ng and Florent Ginhoux and Evan William Newell},
    journal={Nature Biotechnology},
    year={2018},
    volume={37},
    pages={38-44},
    url={https://api.semanticscholar.org/CorpusID:54473203}
}

@article{maaten2008tsne,
    title={Visualizing Data using t-SNE},
    author={Laurens van der Maaten and Geoffrey E. Hinton},
    journal={Journal of Machine Learning Research},
    year={2008},
    volume={9},
    pages={2579-2605},
    url={https://api.semanticscholar.org/CorpusID:5855042}
}

@article{gewers2021pca,
    title={Principal Component Analysis: A Natural Approach to Data Exploration},
    volume={54},
    ISSN={1557-7341},
    url={http://dx.doi.org/10.1145/3447755},
    DOI={10.1145/3447755},
    number={4},
    journal={ACM Computing Surveys},
    publisher={Association for Computing Machinery (ACM)},
    author={Gewers, Felipe L. and Ferreira, Gustavo R. and Arruda, Henrique F. De and Silva, Filipi N. and Comin, Cesar H. and Amancio, Diego R. and Costa, Luciano Da F.},
    year={2021},
    month=may, pages={1–34} 
}

@techreport{sewell2008pca,
    title={Principal Component Analysis},
    url={http://www.stats.org.uk/pca/pca.pdf},
    author={Martin Sewell},
    institution = {University College London},
    year={2008},
    month=jan, 
}

@article{yang2021dimensionality,
    title = {Dimensionality reduction by UMAP reinforces sample heterogeneity analysis in bulk transcriptomic data},
    journal = {Cell Reports},
    volume = {36},
    number = {4},
    pages = {109442},
    year = {2021},
    issn = {2211-1247},
    doi = {https://doi.org/10.1016/j.celrep.2021.109442},
    url = {https://www.sciencedirect.com/science/article/pii/S2211124721008597},
    author = {Yang Yang and Hongjian Sun and Yu Zhang and Tiefu Zhang and Jialei Gong and Yunbo Wei and Yong-Gang Duan and Minglei Shu and Yuchen Yang and Di Wu and Di Yu},
    keywords = {bulk transcriptomics, dimensionality reduction, UMAP, t-SNE, PCA, clustering structure, heterogeneity analysis},
    abstract = {Summary
    Transcriptomic analysis plays a key role in biomedical research. Linear dimensionality reduction methods, especially principal-component analysis (PCA), are widely used in detecting sample-to-sample heterogeneity, while recently developed non-linear methods, such as t-distributed stochastic neighbor embedding (t-SNE) and uniform manifold approximation and projection (UMAP), can efficiently cluster heterogeneous samples in single-cell RNA sequencing analysis. Yet, the application of t-SNE and UMAP in bulk transcriptomic analysis and comparison with conventional methods have not been achieved. We compare four major dimensionality reduction methods (PCA, multidimensional scaling [MDS], t-SNE, and UMAP) in analyzing 71 large bulk transcriptomic datasets. UMAP is superior to PCA and MDS but shows some advantages over t-SNE in differentiating batch effects, identifying pre-defined biological groups, and revealing in-depth clusters in two-dimensional space. Importantly, UMAP generates sample clusters uncovering biological features and clinical meaning. We recommend deploying UMAP in visualizing and analyzing sizable bulk transcriptomic datasets to reinforce sample heterogeneity analysis.}
}

@misc{wang2021understanding,
    title={Understanding How Dimension Reduction Tools Work: An Empirical Approach to Deciphering t-SNE, UMAP, TriMAP, and PaCMAP for Data Visualization}, 
    author={Yingfan Wang and Haiyang Huang and Cynthia Rudin and Yaron Shaposhnik},
    year={2021},
    eprint={2012.04456},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    url={https://arxiv.org/abs/2012.04456}, 
}

@misc{mcinnes2020umapuniformmanifoldapproximation,
      title={UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction}, 
      author={Leland McInnes and John Healy and James Melville},
      year={2020},
      eprint={1802.03426},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1802.03426}, 
}

@Article{torgerson1952mds,
    title={Multidimensional scaling: I. Theory and method},
    author={Warren S. Torgerson},
    journal={Psychometrika},
    year={1952},
    volume={17},
    pages={401-419},
    url={https://api.semanticscholar.org/CorpusID:120849755}
}

@inproceedings{elzen2011baobabview,
    author={van den Elzen, Stef and van Wijk, Jarke J.},
    booktitle={2011 IEEE Conference on Visual Analytics Science and Technology (VAST)}, 
    title={BaobabView: Interactive construction and analysis of decision trees}, 
    year={2011},
    volume={},
    number={},
    pages={151-160},
    keywords={Data visualization;Decision trees;Histograms;Accuracy;Impurities;Algorithm design and analysis;Training},
    doi={10.1109/VAST.2011.6102453}
}

@misc{mrva2019decision,
    title={Decision Support in Medical Data Using 3D Decision Tree Visualisation},
    author={Jakub Mrva and Štefan Neupauer and Lukáš Hudec and Jakub Ševcech and Peter Kapec},
    journal={2019 E-Health and Bioengineering Conference (EHB)},
    year={2019},
    pages={1-4},
    url={https://api.semanticscholar.org/CorpusID:210970801}
}

@misc{szucs2018decision,
    author = {Szücs, Dora and Schmidt, Florian},
    year = {2018},
    month = {10},
    pages = {190-195},
    title = {Decision Tree Visualization for High-Dimensional Numerical Data},
    doi = {10.1109/SNAMS.2018.8554961}
}

@inbook{fisher2012making,
    author = {Danyel Fisher and Miriah Meyer},
    title = {Multiple and Coordinated Views},
    booktitle = {Making Data Visual: A Practical Guide to Using Visualization for Insight},
    chapter = {6},
    publisher = {O'Reilly Media},
    year = {2012},
    url={https://www.oreilly.com/library/view/making-data-visual/9781491960493/}
}

@misc{ming2019rulematrix,
    title={RuleMatrix: Visualizing and Understanding Classifiers with Rules}, 
    author={Yao Ming and Huamin Qu and Enrico Bertini},
    year={2018},
    eprint={1807.06228},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    url={https://arxiv.org/abs/1807.06228}, 
}

@misc{wang2022timbertrek,
    title={TimberTrek: Exploring and Curating Sparse Decision Trees with Interactive Visualization},
    url={http://dx.doi.org/10.1109/VIS54862.2022.00021},
    DOI={10.1109/vis54862.2022.00021},
    booktitle={2022 IEEE Visualization and Visual Analytics (VIS)},
    publisher={IEEE},
    author={Wang, Zijie J. and Zhong, Chudi and Xin, Rui and Takagi, Takuya and Chen, Zhi and Chau, Duen Horng and Rudin, Cynthia and Seltzer, Margo},
    year={2022},
    month=oct, 
    pages={60–64} 
}

@article{schulz2011treevis,
    title={Treevis.net: A Tree Visualization Reference},
    author={Hans-J{\"o}rg Schulz},
    journal={IEEE Computer Graphics and Applications},
    year={2011},
    volume={31},
    pages={11-15},
    url={https://api.semanticscholar.org/CorpusID:8225504}
}

@misc{shapDocumentationOnline,
    author = {Scott Lundberg},
    title = {SHAP online documentation},
    howpublished = {Observable},
    year = {2022},
    url = {https://shap.readthedocs.io/en/latest/api_examples.html#plots}
}

@misc{parr2019dtreeviz,
    author = {T. Parr and P. Grover},
    title = {How to visualize decision trees},
    howpublished = {explained.ai},
    year = {2019},
    url = {https://explained.ai/decision-tree-viz/}
}

@misc{plonski2021visualize,
    author = {P. Płoński},
    title = {How to visualize Decision Tree in {Python} (scikit-learn)},
    howpublished = {MLJAR Blog},
    year = {2021},
    url = {https://mljar.com/blog/visualize-decision-tree/}
}

@misc{joesquito2024decision,
    author = {joesquito},
    title = {Decision Tables},
    howpublished = {Observable},
    year = {2024},
    url = {https://observablehq.com/@joesquito/decision-table}
}

@techreport{breiman2002manual,
    author = {Leo Breiman},
    title = {Manual on Setting Up, Using, and Understanding Random Forests v3.1},
    institution = {University of California, Berkeley},
    year = {2002},
    number = {4(1):29},
    url = {https://www.stat.berkeley.edu/~breiman/Using_random_forests_V3.1.pdf}
}

@misc{kovalerchuk2019interactive,
    title={Interactive Decision Tree Creation and Enhancement with Complete Visualization for Explainable Modeling}, 
    author={Boris Kovalerchuk Andrew Dunn and Alex Worland and Sridevi Wagle},
    year={2023},
    eprint={2305.18432},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    url={https://arxiv.org/abs/2305.18432}, 
}

@ARTICLE{8022871,
  author={Kahng, Minsuk and Andrews, Pierre Y. and Kalro, Aditya and Chau, Duen Horng},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={ActiVis: Visual Exploration of Industry-Scale Deep Neural Network Models}, 
  year={2018},
  volume={24},
  number={1},
  pages={88-97},
  keywords={Computational modeling;Tools;Machine learning;Data models;Neurons;Facebook;Data visualization;Visual analytics;deep learning;machine learning;information visualization},
  doi={10.1109/TVCG.2017.2744718}}

@article{Chatzimparmpas_2020,
   title={The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations},
   volume={39},
   ISSN={1467-8659},
   url={http://dx.doi.org/10.1111/cgf.14034},
   DOI={10.1111/cgf.14034},
   number={3},
   journal={Computer Graphics Forum},
   publisher={Wiley},
   author={Chatzimparmpas, A. and Martins, R. M. and Jusufi, I. and Kucher, K. and Rossi, F. and Kerren, A.},
   year={2020},
   month=jun, pages={713–756} }

@ARTICLE{7536654,
  author={Liu, Mengchen and Shi, Jiaxin and Li, Zhen and Li, Chongxuan and Zhu, Jun and Liu, Shixia},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Towards Better Analysis of Deep Convolutional Neural Networks}, 
  year={2017},
  volume={23},
  number={1},
  pages={91-100},
  keywords={Neurons;Neural networks;Training;Visual analytics;Clustering algorithms;Image edge detection;Deep convolutional neural networks;rectangle packing;matrix reordering;edge bundling;biclustering},
  doi={10.1109/TVCG.2016.2598831}}

@article{AZODI2020442,
title = {Opening the Black Box: Interpretable Machine Learning for Geneticists},
journal = {Trends in Genetics},
volume = {36},
number = {6},
pages = {442-455},
year = {2020},
issn = {0168-9525},
doi = {https://doi.org/10.1016/j.tig.2020.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S016895252030069X},
author = {Christina B. Azodi and Jiliang Tang and Shin-Han Shiu},
keywords = {interpretable machine learning, deep learning, predictive biology},
abstract = {Because of its ability to find complex patterns in high dimensional and heterogeneous data, machine learning (ML) has emerged as a critical tool for making sense of the growing amount of genetic and genomic data available. While the complexity of ML models is what makes them powerful, it also makes them difficult to interpret. Fortunately, efforts to develop approaches that make the inner workings of ML models understandable to humans have improved our ability to make novel biological insights. Here, we discuss the importance of interpretable ML, different strategies for interpreting ML models, and examples of how these strategies have been applied. Finally, we identify challenges and promising future directions for interpretable ML in genetics and genomics.}
}

@incollection{Dağlarli20,
author = {Evren Dağlarli},
title = {Explainable Artificial Intelligence (xAI) Approaches and Deep Meta-Learning Models},
booktitle = {Advances and Applications in Deep Learning},
publisher = {IntechOpen},
address = {Rijeka},
year = {2020},
editor = {Marco Antonio Aceves-Fernandez},
chapter = {5},
doi = {10.5772/intechopen.92172},
url = {https://doi.org/10.5772/intechopen.92172}
}

@misc{Biran2017ExplanationAJ,
  title={Explanation and Justification in Machine Learning : A Survey Or},
  author={Or Biran and Courtenay V. Cotton},
  year={2017},
  url={https://api.semanticscholar.org/CorpusID:3911355},
  booktitle = {}
}

@article{Letham_2015,
   title={Interpretable classifiers using rules and Bayesian analysis: Building a better stroke prediction model},
   volume={9},
   ISSN={1932-6157},
   url={http://dx.doi.org/10.1214/15-AOAS848},
   DOI={10.1214/15-aoas848},
   number={3},
   journal={The Annals of Applied Statistics},
   publisher={Institute of Mathematical Statistics},
   author={Letham, Benjamin and Rudin, Cynthia and McCormick, Tyler H. and Madigan, David},
   year={2015},
   month=sep }

@misc{Spivak2009METRICRO,
  title={METRIC REALIZATION OF FUZZY SIMPLICIAL SETS},
  author={David I. Spivak},
  year={2009},
  url={https://api.semanticscholar.org/CorpusID:35883069},
  booktitle = {}
}

@inproceedings{10.1145/2783258.2788613,
author = {Caruana, Rich and Lou, Yin and Gehrke, Johannes and Koch, Paul and Sturm, Marc and Elhadad, Noemie},
title = {Intelligible Models for HealthCare: Predicting Pneumonia Risk and Hospital 30-day Readmission},
year = {2015},
isbn = {9781450336642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2783258.2788613},
doi = {10.1145/2783258.2788613},
abstract = {In machine learning often a tradeoff must be made between accuracy and intelligibility. More accurate models such as boosted trees, random forests, and neural nets usually are not intelligible, but more intelligible models such as logistic regression, naive-Bayes, and single decision trees often have significantly worse accuracy. This tradeoff sometimes limits the accuracy of models that can be applied in mission-critical applications such as healthcare where being able to understand, validate, edit, and trust a learned model is important. We present two case studies where high-performance generalized additive models with pairwise interactions (GA2Ms) are applied to real healthcare problems yielding intelligible models with state-of-the-art accuracy. In the pneumonia risk prediction case study, the intelligible model uncovers surprising patterns in the data that previously had prevented complex learned models from being fielded in this domain, but because it is intelligible and modular allows these patterns to be recognized and removed. In the 30-day hospital readmission case study, we show that the same methods scale to large datasets containing hundreds of thousands of patients and thousands of attributes while remaining intelligible and providing accuracy comparable to the best (unintelligible) machine learning methods.},
booktitle = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1721–1730},
numpages = {10},
keywords = {additive models, classification, healthcare, intelligibility, interaction detection, logistic regression, risk prediction},
location = {Sydney, NSW, Australia},
series = {KDD '15}
}

@misc{lin2022generalizedscalableoptimalsparse,
      title={Generalized and Scalable Optimal Sparse Decision Trees}, 
      author={Jimmy Lin and Chudi Zhong and Diane Hu and Cynthia Rudin and Margo Seltzer},
      year={2022},
      eprint={2006.08690},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2006.08690}, 
}

@misc{ustun2019learningoptimizedriskscores,
      title={Learning Optimized Risk Scores}, 
      author={Berk Ustun and Cynthia Rudin},
      year={2019},
      eprint={1610.00168},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1610.00168}, 
}

@InProceedings{10.1007/978-3-540-74205-0_121,
author="Xu, Yonghong
and Hong, Wenxue
and Chen, Na
and Li, Xin
and Liu, WenYuan
and Zhang, Tao",
editor="Huang, De-Shuang
and Heutte, Laurent
and Loog, Marco",
title="Parallel Filter: A Visual Classifier Based on Parallel Coordinates and Multivariate Data Analysis",
booktitle="Advanced Intelligent Computing Theories and Applications. With Aspects of Artificial Intelligence",
year="2007",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1172--1183",
abstract="Multivariate visualization techniques are often used as assistant tools for classification tasks up to now. However, few classification systems fully utilize the capability of multivariate visualization and integrate them with multivariate analysis algorithms into a compact system. We propose an interactive visual classification model based on some multivariate graphical presentation in this paper. As an example of it, a visual classifier based on parallel coordinates plot is developed. The multivariate data is first mapped to the parallel coordinates plot, and then an optimizer based on linear discriminant analysis optimizes it into the visualization more fit for classification tasks. This optimized visualization then can be processed by decision tree algorithm and attain classification rules. It has the merit of making the invisible visible and users can steer the classification process, consequently favor the understanding and knowledge discovery of original data.",
isbn="978-3-540-74205-0"
}

@inproceedings{10.1145/956750.956837,
author = {Teoh, Soon Tee and Ma, Kwan-Liu},
title = {PaintingClass: interactive construction, visualization and exploration of decision trees},
year = {2003},
isbn = {1581137370},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/956750.956837},
doi = {10.1145/956750.956837},
abstract = {Decision trees are commonly used for classification. We propose to use decision trees not just for classification but also for the wider purpose of knowledge discovery, because visualizing the decision tree can reveal much valuable information in the data. We introduce PaintingClass, a system for interactive construction, visualization and exploration of decision trees. PaintingClass provides an intuitive layout and convenient navigation of the decision tree. PaintingClass also provides the user the means to interactively construct the decision tree. Each node in the decision tree is displayed as a visual projection of the data. Through actual examples and comparison with other classification methods, we show that the user can effectively use PaintingClass to construct a decision tree and explore the decision tree to gain additional knowledge.},
booktitle = {Proceedings of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {667–672},
numpages = {6},
keywords = {visual data mining, interactive visualization, information visualization, decision trees, classification},
location = {Washington, D.C.},
series = {KDD '03}
}

@inproceedings{Teoh2003StarClassIV,
  title={StarClass: Interactive Visual Classification using Star Coordinates},
  author={Soon Tee Teoh and Kwan-Liu Ma},
  booktitle={SDM},
  year={2003},
  url={https://api.semanticscholar.org/CorpusID:15241816}
}

@book{10.5555/383784,
    author = {Fayyad, Usama and Grinstein, Georges G. and Wierse, Andreas},
    title = {Information visualization in data mining and knowledge discovery},
    year = {2001},
    isbn = {1558606890},
    publisher = {Morgan Kaufmann Publishers Inc.},
    address = {San Francisco, CA, USA}
}

@article{10.1145/102377.115768,
author = {Shneiderman, Ben},
title = {Tree visualization with tree-maps: 2-d space-filling approach},
year = {1992},
issue_date = {Jan. 1992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {1},
issn = {0730-0301},
url = {https://doi.org/10.1145/102377.115768},
doi = {10.1145/102377.115768},
journal = {ACM Trans. Graph.},
month = jan,
pages = {92–99},
numpages = {8}
}

@inproceedings{10.1145/1377676.1377683,
author = {Onak, Krzysztof and Sidiropoulos, Anastasios},
title = {Circular partitions with applications to visualization and embeddings},
year = {2008},
isbn = {9781605580715},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1377676.1377683},
doi = {10.1145/1377676.1377683},
abstract = {We introduce a hierarchical partitioning scheme of the Euclidean plane, called circular partitions. Such a partition consists of a hierarchy of convex polygons, each having small aspect ratio, and satisfying specified volume constraints. We apply these partitions to obtain a natural extension of the popular Treemap visualization method. Our proposed algorithm is not constrained in using only rectangles, and can achieve provably better guarantees on the aspect ratio of the constructed polygons.Under relaxed conditions, we can also construct circular partitions in higher-dimensional spaces. We use these relaxed partitions to obtain improved approximation algorithms for embedding ultrametrics into d-dimensional Euclidean space. In particular, we give a polylog(Delta)-approximation algorithm for embedding n-point ultrametrics into R^d with minimum distortion (Delta denotes the spread of the metric). The previously best-known approximation ratio for this problem was polynomial in n [Badoiu et al. SoCG 2006]. This is the first algorithm for embedding a non-trivial family of weighted graph metrics into a space of constant dimension that achieves polylogarithmic approximation ratio.},
booktitle = {Proceedings of the Twenty-Fourth Annual Symposium on Computational Geometry},
pages = {28–37},
numpages = {10},
keywords = {approximation algorithms, embeddings, treemap, ultrametrics, visualization},
location = {College Park, MD, USA},
series = {SCG '08}
}

@article{10.1007/s00371-023-02864-4,
author = {Yao, Yuyou and Li, Tao and Wu, Wenming and Zhang, Gaofeng and Zheng, Liping},
title = {PowerHierarchy: visualization approach of hierarchical data via power diagram},
year = {2023},
issue_date = {Mar 2024},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {40},
number = {3},
issn = {0178-2789},
url = {https://doi.org/10.1007/s00371-023-02864-4},
doi = {10.1007/s00371-023-02864-4},
abstract = {Voronoi treemaps are widely used for hierarchical data visualization. Existing methods calculate the visualization layouts of hierarchical data by combining the proportion optimization of weights and Lloyd’s method of sites. However, this may not only produce results with large area errors but also require more time consumption. Besides, the relative visualization position of the same data element between adjacent frames in dynamic hierarchical data may be changed abruptly, resulting in unclear visual results. To this end, we propose an efficient and topological structure preserved visualization approach, called PowerHierarchy, for visualizing hierarchical data. Firstly, an improved version of the power diagram computing algorithm is introduced to generate the visualization layouts of each data element in the hierarchy. Unlike random initialization, we construct a centroidal Voronoi tessellation as input and then use a Breadth-First traversing strategy to adapt the depth information to produce visual layouts of static hierarchical data. Based on this, an updating scheme is presented for visualizing dynamic hierarchical data, where previous results are iteratively fed as inputs to initialize current layouts. Besides, the external boundary sites and their subsites are projected onto the visual boundary and then moved into the visual region with the relative position preserved. Experimental results on several datasets demonstrate the efficiency, accuracy, and topology preservation advantage of our proposed visualization approach.},
journal = {Vis. Comput.},
month = may,
pages = {1499–1514},
numpages = {16},
keywords = {Power diagram, Treemap, Hierarchical data, Visualization}
}

@ARTICLE{8017613,
  author={Görtler, Jochen and Schulz, Christoph and Weiskopf, Daniel and Deussen, Oliver},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Bubble Treemaps for Uncertainty Visualization}, 
  year={2018},
  volume={24},
  number={1},
  pages={719-728},
  keywords={Uncertainty;Data visualization;Layout;Visualization;Computational modeling;Standards;Indexes;Uncertainty visualization;hierarchy visualization;treemaps;tree layout;circle packing;contours},
  doi={10.1109/TVCG.2017.2743959}}

@INPROCEEDINGS{885091,
  author={Stasko, J. and Zhang, E.},
  booktitle={IEEE Symposium on Information Visualization 2000. INFOVIS 2000. Proceedings}, 
  title={Focus+context display and navigation techniques for enhancing radial, space-filling hierarchy visualizations}, 
  year={2000},
  volume={},
  number={},
  pages={57-65},
  keywords={Navigation;Visualization;File systems;Educational institutions;Computer displays;Space technology;Organization Charts;Geometry},
  doi={10.1109/INFVIS.2000.885091}}

@book{readingsInformationVi,
author = {Card, Stuart and Mackinlay, Jock and Shneiderman, Ben},
year = {1999},
month = {01},
pages = {},
title = {Readings in Information Visualization: Using Vision To Think},
isbn = {978-1-55860-533-6},
journal = {Information Visualization - IVS},
publisher = {Academic Press}
}

@article{Streeb2021TaskBasedVI,
  title={Task-Based Visual Interactive Modeling: Decision Trees and Rule-Based Classifiers},
  author={Dirk Streeb and Yannick Metz and Udo Schlegel and Bruno Schneider and Mennatallah El-Assady and Hansj{\"o}rg Neth and Min Chen and Daniel A. Keim},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  year={2021},
  volume={28},
  pages={3307-3323},
  url={https://api.semanticscholar.org/CorpusID:231604534}
}

@article{Fan2020ClassificationAV,
  title={Classification Acceleration via Merging Decision Trees},
  author={Chenglin Fan and P. Li},
  journal={Proceedings of the 2020 ACM-IMS on Foundations of Data Science Conference},
  year={2020},
  url={https://api.semanticscholar.org/CorpusID:224805052}
}

@article{Fortin2012DEAPEA,
  title={DEAP: evolutionary algorithms made easy},
  author={F{\'e}lix-Antoine Fortin and François-Michel De Rainville and Marc-Andr{\'e} Gardner and Marc Parizeau and Christian Gagn{\'e}},
  journal={J. Mach. Learn. Res.},
  year={2012},
  volume={13},
  pages={2171-2175},
  url={https://api.semanticscholar.org/CorpusID:15629107}
}

@book{IntroductiontoDataMining,
author = {Tan and Pang-Ning and Steinbach and Michael and Adeyeye Oshin and Michael and Kumar and Vipin and Vipin},
year = {2005},
month = {05},
pages = {},
title = {Introduction to Data Mining},
publisher = {Addison Wesley}
}

@article{ClassificationandRegressionTrees,
author = {Loh, Wei-Yin},
year = {2011},
month = {01},
pages = {14 - 23},
title = {Classification and Regression Trees},
volume = {1},
journal = {Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
doi = {10.1002/widm.8}
}

@misc{samimi2025visualconversationalinterfaceevidencebasedexplanation,
      title={Visual-Conversational Interface for Evidence-Based Explanation of Diabetes Risk Prediction}, 
      author={Reza Samimi and Aditya Bhattacharya and Lucija Gosak and Gregor Stiglic and Katrien Verbert},
      year={2025},
      eprint={2507.02920},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2507.02920}, 
}

@misc{yan2025vislixxaiframeworkvalidating,
      title={VISLIX: An XAI Framework for Validating Vision Models with Slice Discovery and Analysis}, 
      author={Xinyuan Yan and Xiwei Xuan and Jorge Piazentin Ono and Jiajing Guo and Vikram Mohanty and Shekar Arvind Kumar and Liang Gou and Bei Wang and Liu Ren},
      year={2025},
      eprint={2505.03132},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2505.03132}, 
}

@Article{analytics4010007,
AUTHOR = {Kucher, Kostiantyn and Zohrevandi, Elmira and Westin, Carl A. L.},
TITLE = {Towards Visual Analytics for Explainable AI in Industrial Applications},
JOURNAL = {Analytics},
VOLUME = {4},
YEAR = {2025},
NUMBER = {1},
ARTICLE-NUMBER = {7},
URL = {https://www.mdpi.com/2813-2203/4/1/7},
ISSN = {2813-2203},
ABSTRACT = {As the levels of automation and reliance on modern artificial intelligence (AI) approaches increase across multiple industries, the importance of the human-centered perspective becomes more evident. Various actors in such industrial applications, including equipment operators and decision makers, have their needs and preferences that often do not align with the decisions produced by black-box models, potentially leading to mistrust and wasted productivity gain opportunities. In this paper, we examine these issues through the lenses of visual analytics and, more broadly, interactive visualization, and we argue that the methods and techniques from these fields can lead to advances in both academic research and industrial innovations concerning the explainability of AI models. To address the existing gap within and across the research and application fields, we propose a conceptual framework for visual analytics design and evaluation for such scenarios, followed by a preliminary roadmap and call to action for the respective communities.},
DOI = {10.3390/analytics4010007}
}

@misc{cappuccio2024fipervisualbasedexplanationcombining,
      title={Fiper: a Visual-based Explanation Combining Rules and Feature Importance}, 
      author={Eleonora Cappuccio and Daniele Fadda and Rosa Lanzilotti and Salvatore Rinzivillo},
      year={2024},
      eprint={2404.16903},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2404.16903}, 
}

@article{Chatzimparmpas2023DeforestVisBA,
  title={DeforestVis: Behaviour Analysis of Machine Learning Models with Surrogate Decision Stumps},
  author={Angelos Chatzimparmpas and Rafael Messias Martins and Alexandru Cristian Telea and Andreas Kerren},
  journal={Computer Graphics Forum},
  year={2023},
  volume={43},
  url={https://api.semanticscholar.org/CorpusID:257912686}
}

@inproceedings{UnlockingPowerExplainabilityRankingSystemsAVisualAnalytics,
author = {Salimiparasa, Mozhgan and Sedig, Kamran and Lizotte, Daniel},
year = {2024},
month = {02},
pages = {3-13},
title = {Unlocking the Power of Explainability in Ranking Systems: A Visual Analytics Approach with XAI Techniques},
isbn = {978-3-031-54302-9},
doi = {10.1007/978-3-031-54303-6_1},
booktitle = {Explainable Artificial Intelligence and Process Mining Applications for Healthcare}
}

@article{Z_ller_2023,
   title={XAutoML: A Visual Analytics Tool for Understanding and Validating Automated Machine Learning},
   volume={13},
   ISSN={2160-6463},
   url={http://dx.doi.org/10.1145/3625240},
   DOI={10.1145/3625240},
   number={4},
   journal={ACM Transactions on Interactive Intelligent Systems},
   publisher={Association for Computing Machinery (ACM)},
   author={Zöller, Marc-André and Titov, Waldemar and Schlegel, Thomas and Huber, Marco F.},
   year={2023},
   month=dec, pages={1–39} }

@ARTICLE{9861728,
author={Yuan, Jun and Chan, Gromit Yeuk-Yin and Barr, Brian and Overton, Kyle and Rees, Kim and Nonato, Luis Gustavo and Bertini, Enrico and Silva, Claudio T.},
journal={IEEE Computer Graphics and Applications}, 
title={SUBPLEX: A Visual Analytics Approach to Understand Local Model Explanations at the Subpopulation Level}, 
year={2022},
volume={42},
number={6},
pages={24-36},
keywords={Analytical models;Visual analytics;Task analysis;Data visualization;Data models;Human in the loop;Computational modeling},
doi={10.1109/MCG.2022.3199727}}

@ARTICLE{8807299,
author={Spinner, Thilo and Schlegel, Udo and Schäfer, Hanna and El-Assady, Mennatallah},
journal={IEEE Transactions on Visualization and Computer Graphics}, 
title={explAIner: A Visual Analytics Framework for Interactive and Explainable Machine Learning}, 
year={2020},
volume={26},
number={1},
pages={1064-1074},
keywords={Data models;Analytical models;Computational modeling;Pipelines;Machine learning;Monitoring;Explainable AI;Interactive Machine Learning;Deep Learning;Visual Analytics;Interpretability;Explainability},
doi={10.1109/TVCG.2019.2934629}}

@inproceedings{10.1145/2939672.2939778,
author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
title = {"Why Should I Trust You?": Explaining the Predictions of Any Classifier},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939778},
doi = {10.1145/2939672.2939778},
abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one.In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally varound the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1135–1144},
numpages = {10},
keywords = {black box classifier, explaining machine learning, interpretability, interpretable machine learning},
location = {San Francisco, California, USA},
series = {KDD '16}
}

@article{Selvaraju_2019,
   title={Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization},
   volume={128},
   ISSN={1573-1405},
   url={http://dx.doi.org/10.1007/s11263-019-01228-7},
   DOI={10.1007/s11263-019-01228-7},
   number={2},
   journal={International Journal of Computer Vision},
   publisher={Springer Science and Business Media LLC},
   author={Selvaraju, Ramprasaath R. and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
   year={2019},
   month=oct, pages={336–359} }

@article{Bach2015OnPE,
  title={On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation},
  author={Sebastian Bach and Alexander Binder and Gr{\'e}goire Montavon and Frederick Klauschen and Klaus-Robert M{\"u}ller and Wojciech Samek},
  journal={PLoS ONE},
  year={2015},
  volume={10},
  url={https://api.semanticscholar.org/CorpusID:9327892}
}

@inproceedings{10.1145/3278721.3278725,
author = {Tan, Sarah and Caruana, Rich and Hooker, Giles and Lou, Yin},
title = {Distill-and-Compare: Auditing Black-Box Models Using Transparent Model Distillation},
year = {2018},
isbn = {9781450360128},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3278721.3278725},
doi = {10.1145/3278721.3278725},
abstract = {Black-box risk scoring models permeate our lives, yet are typically proprietary or opaque. We propose Distill-and-Compare, an approach to audit such models without probing the black-box model API or pre-defining features to audit. To gain insight into black-box models, we treat them as teachers, training transparent student models to mimic the risk scores assigned by the black-box models. We compare the mimic model trained with distillation to a second, un-distilled transparent model trained on ground truth outcomes, and use differences between the two models to gain insight into the black-box model. We demonstrate the approach on four data sets: COMPAS, Stop-and-Frisk, Chicago Police, and Lending Club. We also propose a statistical test to determine if a data set is missing key features used to train the black-box model. Our test finds that the ProPublica data is likely missing key feature(s) used in COMPAS.},
booktitle = {Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {303–310},
numpages = {8},
keywords = {black-box models, distillation, fairness, interpretability},
location = {New Orleans, LA, USA},
series = {AIES '18}
}

@misc{shrikumar2019learningimportantfeaturespropagating,
      title={Learning Important Features Through Propagating Activation Differences}, 
      author={Avanti Shrikumar and Peyton Greenside and Anshul Kundaje},
      year={2019},
      eprint={1704.02685},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1704.02685}, 
}

@misc{sundararajan2017axiomaticattributiondeepnetworks,
      title={Axiomatic Attribution for Deep Networks}, 
      author={Mukund Sundararajan and Ankur Taly and Qiqi Yan},
      year={2017},
      eprint={1703.01365},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1703.01365}, 
}

@misc{simonyan2014deepinsideconvolutionalnetworks,
      title={Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps}, 
      author={Karen Simonyan and Andrea Vedaldi and Andrew Zisserman},
      year={2014},
      eprint={1312.6034},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1312.6034}, 
}

@inproceedings{10.5555/3504035.3504222,
author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
title = {Anchors: high-precision model-agnostic explanations},
year = {2018},
isbn = {978-1-57735-800-8},
publisher = {AAAI Press},
abstract = {We introduce a novel model-agnostic system that explains the behavior of complex models with high-precision rules called anchors, representing local, "sufficient" conditions for predictions. We propose an algorithm to efficiently compute these explanations for any black-box model with high-probability guarantees. We demonstrate the flexibility of anchors by explaining a myriad of different models for different domains and tasks. In a user study, we show that anchors enable users to predict how a model would behave on unseen instances with less effort and higher precision, as compared to existing linear explanations or no explanations.},
booktitle = {Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence and Thirtieth Innovative Applications of Artificial Intelligence Conference and Eighth AAAI Symposium on Educational Advances in Artificial Intelligence},
articleno = {187},
numpages = {9},
location = {New Orleans, Louisiana, USA},
series = {AAAI'18/IAAI'18/EAAI'18}
}

@INPROCEEDINGS{7780688,
  author={Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Learning Deep Features for Discriminative Localization}, 
  year={2016},
  volume={},
  number={},
  pages={2921-2929},
  keywords={Visualization;Neural networks;Training;Object recognition;Computer vision;Detectors;Spatial resolution},
  doi={10.1109/CVPR.2016.319}}

@misc{limegeeksforgeeks,
    author = {geeksforgeeks},
    title = {Explainable AI(XAI) Using LIME},
    howpublished = {Observable},
    year = {2025},
    url = {https://www.geeksforgeeks.org/artificial-intelligence/introduction-to-explainable-aixai-using-lime/}
}

@article{Breiman1984ClassificationAR,
  title={Classification and Regression Trees},
  author={L. Breiman and Jerome H. Friedman and Richard A. Olshen and C. J. Stone},
  journal={Biometrics},
  year={1984},
  volume={40},
  pages={874},
  url={https://api.semanticscholar.org/CorpusID:29458883}
}

@inproceedings{10.1609/aaai.v33i01.330110035,
author = {Sokol, Kacper and Flach, Peter},
title = {Desiderata for interpretability: explaining decision tree predictions with counterfactuals},
year = {2019},
isbn = {978-1-57735-809-1},
publisher = {AAAI Press},
url = {https://doi.org/10.1609/aaai.v33i01.330110035},
doi = {10.1609/aaai.v33i01.330110035},
abstract = {Explanations in machine learning come in many forms, but a consensus regarding their desired properties is still emerging. In our work we collect and organise these explainability desiderata and discuss how they can be used to systematically evaluate properties and quality of an explainable system using the case of class-contrastive counterfactual statements. This leads us to propose a novel method for explaining predictions of a decision tree with counterfactuals. We show that our model-specific approach exploits all the theoretical advantages of counterfactual explanations, hence improves decision tree interpretability by decoupling the quality of the interpretation from the depth and width of the tree.},
booktitle = {Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence and Thirty-First Innovative Applications of Artificial Intelligence Conference and Ninth AAAI Symposium on Educational Advances in Artificial Intelligence},
articleno = {1316},
numpages = {2},
location = {Honolulu, Hawaii, USA},
series = {AAAI'19/IAAI'19/EAAI'19}
}

@article{Wexler2019TheWT,
  title={The What-If Tool: Interactive Probing of Machine Learning Models},
  author={James Wexler and Mahima Pushkarna and Tolga Bolukbasi and Martin Wattenberg and Fernanda B. Vi{\'e}gas and Jimbo Wilson},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  year={2019},
  volume={26},
  pages={56-65},
  url={https://api.semanticscholar.org/CorpusID:195848259}
}




@article{doi:10.1177/14738716231216030,
author = {Vasile Ciorna and Guy Melançon and Frank Petry and Mohammad Ghoniem},
title ={Interact: A visual what-if analysis tool for virtual product design},

journal = {Information Visualization},
volume = {23},
number = {2},
pages = {123-141},
year = {2024},
doi = {10.1177/14738716231216030},

URL = { 
    
        https://doi.org/10.1177/14738716231216030
    
    

},
eprint = { 
    
        https://doi.org/10.1177/14738716231216030
    
    

}
,
    abstract = { Virtual prototyping is increasingly used by businesses to streamline operations, cut costs, and enhance daily operations. This often includes a variety of modeling techniques among which, complex, black-box models. The path from model development to utilization in applied contexts is yet long. Domain experts need to be convinced of the validity of the models and to trust their predictions. To be used in the field, model capabilities need to be affordable, that is, allow rapid and interactive scenario building, even for non-experts. Complex relations governed by statistical interactions must be unveiled for users to understand unexpected predictions. We propose Interact, a model-agnostic, visual what-if tool for regression problems, supporting (1) the visualization of statistical interactions between features, (2) the creation of interactive what-if scenarios using predictive models, (3) the evaluation of model quality and building trust, and (4) the externalization of knowledge through model explainability. While the approach applies in various industrial contexts, we validate the application purpose and design with a detailed case study and a qualitative user study with engineers in the tire industry. By unraveling statistical interactions between features, the INTERACT tool proves to be useful to increase the transparency of black-box machine learning models. We also reflect on lessons learned concerning the development of visual what-if tools for virtual product development and beyond. }
}

@inproceedings{10430533,
  author={Manca, Gianluca and Kunze, Franz C. and Brorsson, Emmanuel and Fay, Alexander},
  booktitle={2023 IEEE 2nd Industrial Electronics Society Annual On-Line Conference (ONCON)}, 
  title={Dynamic Causal Analysis with Operator-Centric Visualization for Managing Industrial Alarm Floods}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  keywords={Industrial electronics;Visualization;Electric potential;Cause effect analysis;Floods;Causal dependencies;fault detection and diagnosis;industrial alarm floods},
  doi={10.1109/ONCON60463.2023.10430533}}


@article{FREUND1997119,
title = {A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting},
journal = {Journal of Computer and System Sciences},
volume = {55},
number = {1},
pages = {119-139},
year = {1997},
issn = {0022-0000},
doi = {https://doi.org/10.1006/jcss.1997.1504},
url = {https://www.sciencedirect.com/science/article/pii/S002200009791504X},
author = {Yoav Freund and Robert E Schapire},
abstract = {In the first part of the paper we consider the problem of dynamically apportioning resources among a set of options in a worst-case on-line framework. The model we study can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting. We show that the multiplicative weight-update Littlestone–Warmuth rule can be adapted to this model, yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems. We show how the resulting learning algorithm can be applied to a variety of problems, including gambling, multiple-outcome prediction, repeated games, and prediction of points in Rn. In the second part of the paper we apply the multiplicative weight-update technique to derive a new boosting algorithm. This boosting algorithm does not require any prior knowledge about the performance of the weak learning algorithm. We also study generalizations of the new boosting algorithm to the problem of learning functions whose range, rather than being binary, is an arbitrary finite set or a bounded segment of the real line.}
}

@article{RAMER1972244,
title = {An iterative procedure for the polygonal approximation of plane curves},
journal = {Computer Graphics and Image Processing},
volume = {1},
number = {3},
pages = {244-256},
year = {1972},
issn = {0146-664X},
doi = {https://doi.org/10.1016/S0146-664X(72)80017-0},
url = {https://www.sciencedirect.com/science/article/pii/S0146664X72800170},
author = {Urs Ramer},
abstract = {The approximation of arbitrary two-dimensional curves by polygons is an importanttechnique in image processing. For many applications, the apparent ideal procedure is to represent lines and boundaries by means of polygons with minimum number of vertices and satisfying a given fit criterion. In this paper, an approximation algorithm is presented which uses an iterative method to produce polygons with a small—but not minimum—number of vertices that lie on the given curve. The maximum distance of the curve from the approximating polygon is chosen as the fit criterion. The results obtained justify the abandonment of the minimum-vertices criterion which is computationally much more expensive.}
}

@article{doi:10.3138/FM57-6770-U75U-7727,
author = {DOUGLAS, DAVID H and PEUCKER, THOMAS K},
title = {ALGORITHMS FOR THE REDUCTION OF THE NUMBER OF POINTS REQUIRED TO REPRESENT A DIGITIZED LINE OR ITS CARICATURE},
journal = {Cartographica},
volume = {10},
number = {2},
pages = {112-122},
year = {1973},
doi = {10.3138/FM57-6770-U75U-7727},

URL = { 
    
        https://doi.org/10.3138/FM57-6770-U75U-7727
    
    

},
eprint = { 
    
        https://doi.org/10.3138/FM57-6770-U75U-7727
    
    

}
,
    abstract = { All digitizing methods, as a general rule, record lines with far more data than is necessary for accurate graphic reproduction or for computer analysis. Two algorithms to reduce the number of points required to represent the line and, if desired, produce caricatures, are presented and compared with the most promising methods so far suggested. Line reduction will form a major part of automated generalization. }
}

@article{Pokojski2018141150,
author = {Pokojski, Wojciech and Pokojska, Paulina},
doi = {10.2478/pcr-2018-0009},
url = {https://doi.org/10.2478/pcr-2018-0009},
title = {Voronoi diagrams – inventor, method, applications},
journal = {Polish Cartographical Review},
number = {3},
volume = {50},
year = {2018},
pages = {141--150}
}


@misc{git1commit,
    author = {Alessandro Carella},
    title = {Git commit: Early protoype of decision tree visualization},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/50ecf96dafc8c9a1955ada30135a54dfa84eaa65}
}

@misc{git2commit,
    author = {Alessandro Carella},
    title = {Git commit: New colors palette},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/f1fa71cd70a6e4497f0aa353ba3632395bd75b4d}
}

@misc{git3commit,
    author = {Alessandro Carella},
    title = {Git commit: Scatter plot first version},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/31aebe09426c54603ce64c833cce69895eb9bac9}
}

@misc{git4commit,
    author = {Alessandro Carella},
    title = {Git commit: Tooltip and click on point functionality for scatter plot},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/75d6b0071d124a3980afed0c6e8d59b69caf3f07}
}

@misc{git5commit,
    author = {Alessandro Carella},
    title = {Git commit: Implemented boundary paths instead of grid for the split of the projected boundaries space using ramer douglas peucker for path approximation},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/e89162e58471838a0536dc9e113aacf8a3371b24}
}

@misc{git6commit,
    author = {Alessandro Carella},
    title = {Git commit: Voronoi tessellation for scatter plot decision boundaries},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/2e491d4facc812e34fb9fbdd61d7e2116918d671}
}

@misc{git7commit,
    author = {Alessandro Carella},
    title = {Git commit: Default set the input value for the input features to the median/mode value},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/ce7625624f85f8b99fea76c919680bbe9f66a5aa}
}

@misc{git8commit,
    author = {Alessandro Carella},
    title = {Git commit: Improved style of the webapp},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/53bff28d5827801b01b2eb4361a054d95a66b438}
}

@misc{git9commit,
    author = {Alessandro Carella},
    title = {Git commit: Scatter plot tooltip implementation},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/7a9da6592c21feaa29102cad8040a25c196d9359}
}

@misc{git10commit,
    author = {Alessandro Carella},
    title = {Git commit: Cross highlighting from scatter plot to decision tree plot},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/432c2a50f62fc4e01a2b01f88b3c80f3f755bd00}
}

@misc{git11commit,
    author = {Alessandro Carella},
    title = {Git commit: Cross highlighting from decision tree plot to scatter plot},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/2d36a769af50dc3b9f99612ee2afeec271bd40c4}
}

@misc{git12commit,
    author = {Alessandro Carella},
    title = {Git commit: Webapp UI improvement},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/8de42ac2f15d8a3d561de021d7417eb57d015480}
}

@misc{git13commit,
    author = {Alessandro Carella},
    title = {Git commit: Colors matching between the 2 plots},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/34e6d503fdcc6a63f50a8a55cc78f03b835a2c84}
}

@misc{git14commit,
    author = {Alessandro Carella},
    title = {Git commit: Explained instance is a star instead of a point in the scatter plot},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/5bb5069bb7932f7ffc5745b849647a7d80019ffe}
}

@misc{git15commit,
    author = {Alessandro Carella},
    title = {Git commit: Allowed the user to change the PCA step and the neighbourhood size from webapp UI},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/1b1a03b115a2704a578f1a76cc55c8cbc2cb5282}
}

@misc{git16commit,
    author = {Alessandro Carella},
    title = {Git commit: Improved webapp UI},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/727a9b3be35af8f704f6a1feada45afccc70771b}
}

@misc{git17commit,
    author = {Alessandro Carella},
    title = {Git commit: Last working implementation with images},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/a07aca4df20502bbdd541a3f815fce1391db404f}
}

@misc{git18commit,
    author = {Alessandro Carella},
    title = {Git commit: Added t-SNE as an option in the scatter plot},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/0b40ca0b97c33ca23834e633cfafc5e505ecf380}
}

@misc{git19commit,
    author = {Alessandro Carella},
    title = {Git commit: Added UMAP and MDS as an option in the scatter plot},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/e0bf5907e567ed3bf24d4e97a7f79dd7a348eeb5}
}

@misc{git20commit,
    author = {Alessandro Carella},
    title = {Git commit: Added switch for different dimension reducing techniques in the scatter plot},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/12aec6a64db3d208a633c36b8e01933cb7abf7e4}
}

@misc{git21commit,
    author = {Alessandro Carella},
    title = {Git commit: Split node highlight},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/23f078473cf832c9fa7069e045d43c3f64d3a914}
}

@misc{git22commit,
    author = {Alessandro Carella},
    title = {Git commit: Constant highlight for the explained instance in the decision tree plot},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/0469c76105d9d975959984df9cdbdd83dd2d6008}
}

@misc{git23commit,
    author = {Alessandro Carella},
    title = {Git commit: Improved tooltip with sklearn-like description},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/bafb21589f70fca670b7aa8c63c76ed23989ed59}
}

@misc{git24commit,
    author = {Alessandro Carella},
    title = {Git commit: Dynamic colors for classes in RGB space},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/79ddcd8630729f96ed8e109ce78232fb7ec5b7c5}
}

@misc{git25commit,
    author = {Alessandro Carella},
    title = {Git commit: Added option to see the dataset points in the scatter plot},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/af1f79008ca8ea8d38e8903be520e6f452311939}
}

@misc{git26commit,
    author = {Alessandro Carella},
    title = {Git commit: First implementation of the tree spawn visualization},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/f8e8d0e9ea249aa4035f1330535e98a70c817988}
}

@misc{git27commit,
    author = {Alessandro Carella},
    title = {Git commit: First implementation of the blocks tree visualization},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/5e711a416bf16f381cedbed764a5a6fb7ad70269}
}

@misc{git28commit,
    author = {Alessandro Carella},
    title = {Git commit: Implementation of the blocks tree visualization using rectangles for the nodes},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/da7896cfd46ad0f250bf1b54c4f010c45b454676}
}

@misc{git29commit,
    author = {Alessandro Carella},
    title = {Git commit: Dynamic font for the text in the rectangles},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/4151678797efc48ddf7086ed9833d621076b6242}
}

@misc{git30commit,
    author = {Alessandro Carella},
    title = {Git commit: Implemented the expansion of the subtrees in the spawn tree visualization},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/202c78cce6144ac3e39bbd5b1f73927bb7e9c452}
}

@misc{git31commit,
    author = {Alessandro Carella},
    title = {Git commit: Improved spacing in the tree spawn visualization},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/12ef4628f0a478a4e4fe3a2574b9253b24787d5d}
}

@misc{git32commit,
    author = {Alessandro Carella},
    title = {Git commit: Integrated spawn tree visualization in the webapp},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/d7b0d4e30e3809be348d2a4b04a3f87d8b8142aa}
}

@misc{git33commit,
    author = {Alessandro Carella},
    title = {Git commit: Integrated tree blocks visualization in the webapp},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/3b6f806a80df6738b5b847ab13aec7ae3ecf7f95}
}

@misc{git34commit,
    author = {Alessandro Carella},
    title = {Git commit: Integration in Jupyter notebook},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://github.com/AlessandroCarella/Master-thesis/tree/c73eafd3c64403f34678241741ccc378b3d922e6}
}

@misc{colorbrewer2ColorPalette,
    author = {Cynthia Brewer and Mark Harrower and The Pennsylvania State University},
    title = {ColorBrewer: Color Advice for Maps},
    howpublished = {Observable},
    year = {2013}, 
    url = {https://colorbrewer2.org/#type=qualitative&scheme=Set3&n=12}
}

@misc{sklearnDecisionTree,
    author = {Arturo Amor and Lucy Liu and Maren Westermann and Yao Xiao},
    title = {Understanding the decision tree structure},
    howpublished = {Observable},
    year = {2010}, 
    url = {https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html}
}

@ARTICLE{1702828,
  author={Reingold, E.M. and Tilford, J.S.},
  journal={IEEE Transactions on Software Engineering}, 
  title={Tidier Drawings of Trees}, 
  year={1981},
  volume={SE-7},
  number={2},
  pages={223-228},
  keywords={Tree data structures;Printing;Binary trees;Computer science;Software algorithms;Engineering drawings;Data structures;trees;tree structures},
  doi={10.1109/TSE.1981.234519}}

@misc{horizontalPartitionChart,
    author = {amcharts},
    title = {Horizontal Partition Chart - amCharts},
    howpublished = {Observable},
    year = {2025}, 
    url = {https://www.amcharts.com/demos/horizontal-partition-chart/}
}