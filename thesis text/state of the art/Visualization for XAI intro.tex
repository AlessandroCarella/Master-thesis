The following section reviews the literature and techniques that inform the development of the thesis visualization system. Since local explainability methods mostly rely on the same principle of generating a synthetic neighborhood and the training of a surrogate model, this review is structured to address the key components of our interactive explanation system. We begin by examining dimensionality reduction techniques that enable visual exploration of high-dimensional synthetic data in a reduced dimensional space. Subsequently, we explore the literature on decision tree visualization, as decision trees constitute the primary surrogate model employed for rule extraction. Finally, we survey existing visual tools and interactive techniques in eXplainable Artificial Intelligence.